{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import pprint\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from lxml import html\n",
    "from io import StringIO\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yuli Gurriel\n",
    "This notebook i'll attempt to make a few lists and iterate through them for the scrape rather than do it manually for each year. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.retrosheet.org/boxesetc/2016/Igurry0010012016.htm',\n",
    "        'https://www.retrosheet.org/boxesetc/2017/Igurry0010022017.htm']\n",
    "\n",
    "csv_names = ['csv_from_scrape/gurriel_2016_df.csv',\n",
    "             'csv_from_scrape/gurriel_2017_df.csv']\n",
    "\n",
    "years = ['2016', '2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, url in enumerate(urls):\n",
    "    \n",
    "    # batting averages\n",
    "\n",
    "    xpath = \"//pre[5]/text()\"\n",
    "    r = requests.get(url)\n",
    "    page = html.parse(StringIO(r.text))\n",
    "    batter = page.xpath(xpath)\n",
    "    \n",
    "    batter_game_data_only = []\n",
    "    for a, row in enumerate(batter):\n",
    "        if a % 2 == 0:\n",
    "            batter_game_data_only.append(row)\n",
    "    \n",
    "    batter_game_data_cleaned = []\n",
    "    for row in batter_game_data_only[1:]:\n",
    "        if len(row) > len(batter_game_data_only[2]):\n",
    "            batter_game_data_cleaned.append(row[0:112])\n",
    "        else:\n",
    "            batter_game_data_cleaned.append(row)\n",
    "        \n",
    "    batter_averages = [float(row[87:91]) for row in batter_game_data_cleaned]\n",
    "\n",
    "    # dates played this year\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    link_text = []\n",
    "    for a in soup.find_all('a'):\n",
    "        link_text.append(a.string)\n",
    "        \n",
    "    batter_dates = []\n",
    "    for i in link_text:\n",
    "        if years[idx] in i:\n",
    "            batter_dates.append(i)\n",
    "            \n",
    "    batter_dates_cleaned = []\n",
    "    for date in batter_dates:\n",
    "        batter_dates_cleaned.append(date.replace(' ', '0'))\n",
    "        \n",
    "    batter_dates_final = []\n",
    "    for date in batter_dates_cleaned:\n",
    "        batter_dates_final.append(datetime.strftime(datetime.strptime(date, '%m-%d-%Y'), '%m-%d'))\n",
    "        \n",
    "    batter_df = pd.DataFrame(batter_averages, batter_dates_final).reset_index()\n",
    "    batter_df.columns = [years[idx], 'Batting Average']\n",
    "    batter_df.to_csv(csv_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
